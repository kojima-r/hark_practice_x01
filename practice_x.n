#!/usr/bin/env batchflow
<?xml version="1.0"?>
<Document>
  <Network type="subnet" name="MAIN">
    <Node name="node_LOOP0_1" type="LOOP0" x="100" y="100">
    </Node>
    <NetOutput name="OUTPUT_1" node="node_LOOP0_1" terminal="OUTPUT_1" object_type="any" description="Dynamic"/>
  </Network>
  <Network type="iterator" name="LOOP0">
    <Node name="node_SourceTracker_1" type="SourceTracker" x="400" y="310">
      <Parameter name="THRESH" type="float" value="32" description="Power threshold for localization results. A localization result with higher power than THRESH is tracked, otherwise ignored."/>
      <Parameter name="PAUSE_LENGTH" type="float" value="1500" description="Life duration of source in ms. When any localization result for a source is found for more than PAUSE_LENGTH / 10 iterations, the source is terminated. [default: 800]"/>
      <Parameter name="MIN_SRC_INTERVAL" type="float" value="30" description="Source interval threshold in degree. When the angle between a localization result and a source is smaller than MIN_SRC_INTERVAL, the same ID is given to the localization result. [default: 20]"/>
      <Parameter name="MIN_ID" type="int" value="0" description="Minimum ID of source locations. MIN_ID should be greater than 0 or equal."/>
      <Parameter name="DEBUG" type="bool" value="false" description="Output debug information if true [default: false]"/>
    </Node>
    <Node name="node_MultiFFT_1" type="MultiFFT" x="580" y="110">
      <Parameter name="LENGTH" type="int" value="512" description="FFT length in sample. [default: 512]"/>
      <Parameter name="WINDOW" type="string" value="CONJ" description="A window function for FFT. WINDOW should be CONJ, HAMMING, RECTANGLE, or HANNING. [default: CONJ]"/>
      <Parameter name="WINDOW_LENGTH" type="int" value="512" description="Window length of the window function. [default: 512]"/>
    </Node>
    <Node name="node_AudioStreamFromMic_1" type="AudioStreamFromMic" x="100" y="140">
      <Parameter name="LENGTH" type="int" value="512" description="The frame length of each channel (in samples) [default: 512]."/>
      <Parameter name="ADVANCE" type="int" value="160" description="The shift length beween adjacent frames (in samples)[default: 160]."/>
      <Parameter name="CHANNEL_COUNT" type="int" value="8" description="The number of channels."/>
      <Parameter name="SAMPLING_RATE" type="int" value="16000" description="Sampling rate (Hz) [default: 16000]."/>
      <Parameter name="DEVICETYPE" type="string" value="WASAPI" description="Device type (WASAPI, WS, RASP24-16, RASP24-32,NETWORK).[default: WASAPI]"/>
      <Parameter name="GAIN" type="string" value="0dB" description="capture gain (dB)  [default: 0dB]."/>
      <Parameter name="DEVICE" type="string" value="TAMAGO" description="Device name or IP address [default: 127.0.0.1]"/>
    </Node>
    <Node name="node_PyCodeExecutor3_1" type="PyCodeExecutor3" x="720" y="240">
      <Parameter name="DIRECTORY_NAME" type="string" value="." description="[optional] The directory name of your python code. It will inserted to sys.path."/>
      <Parameter name="MODULENAME" type="string" value="samplecode" description="Your python module name to import, i.e., your python code file name WITHOUT extension."/>
      <Parameter name="CLASSNAME" type="string" value="HarkNode" description="Your class name to call in this node."/>
      <Parameter name="DEBUG" type="bool" value="false" description="Debug option. If true, it prints input list and output list."/>
    </Node>
    <Node name="node_LocalizeMUSIC_1" type="LocalizeMUSIC" x="750" y="100">
      <Parameter name="MUSIC_ALGORITHM" type="string" value="SEVD" description="Sound Source Localization Algorithm. If SEVD, NOISECM will be ignored"/>
      <Parameter name="TF_CHANNEL_SELECTION" type="object" value="&lt;Vector&lt;int&gt; &gt;" description="Microphone channels for localization. If vacant, all channels will be used."/>
      <Parameter name="LENGTH" type="int" value="512" description="The length of a frame (per channel)."/>
      <Parameter name="SAMPLING_RATE" type="int" value="16000" description="Sampling Rate (Hz)."/>
      <Parameter name="A_MATRIX" type="string" value="tamago_rectf.zip" description="Filename of a transfer function matrix."/>
      <Parameter name="WINDOW" type="int" value="50" description="The number of frames used for calculating a correlation function."/>
      <Parameter name="WINDOW_TYPE" type="string" value="FUTURE" description="Window selection to accumulate a correlation function. If PAST, the past WINDOW frames from the current frame are used for the accumulation. If MIDDLE, the current frame will be the middle of the accumulated frames. If FUTURE, the future WINDOW frames from the current frame are used for the accumulation. FUTURE is the default from version 1.0, but this makes a delay since we have to wait for the future information. PAST generates a internal buffers for the accumulation, which realizes no delay for localization."/>
      <Parameter name="PERIOD" type="int" value="50" description="The period in which the source localization is processed."/>
      <Parameter name="NUM_SOURCE" type="int" value="2" description="Number of sources, which should be less than number of channels."/>
      <Parameter name="MIN_DEG" type="int" value="-180" description="source direction (lower)."/>
      <Parameter name="MAX_DEG" type="int" value="180" description="source direction (higher)."/>
      <Parameter name="LOWER_BOUND_FREQUENCY" type="int" value="500" description="Lower bound of frequency (Hz) used for correlation function calculation."/>
      <Parameter name="UPPER_BOUND_FREQUENCY" type="int" value="2800" description="Upper bound of frequency (Hz) used for correlation function calculation."/>
      <Parameter name="SPECTRUM_WEIGHT_TYPE" type="string" value="Uniform" description="MUSIC spectrum weight for each frequency bin."/>
      <Parameter name="A_CHAR_SCALING" type="float" value="1" description="Scaling factor of the A-Weight with respect to frequency"/>
      <Parameter name="MANUAL_WEIGHT_SPLINE" type="object" value="&lt;Matrix&lt;float&gt; &lt;rows 2&gt; &lt;cols 5&gt; &lt;data 0.0 2000.0 4000.0 6000.0 8000.0 1.0 1.0 1.0 1.0 1.0&gt; &gt;" description="MUSIC spectrum weight for each frequency bin. This is a 2 by M matrix. The first row represents the frequency, and the second row represents the weight gain. &quot;M&quot; represents the number of key points for the spectrum weight. The frequency range between M key points will be interpolated by spline manner. The format is &quot;&amp;lt;Matrix&amp;lt;float&amp;gt; &amp;lt;rows 2&amp;gt; &amp;lt;cols 2&amp;gt; &amp;lt;data 1 2 3 4&amp;gt; &amp;gt;&quot;."/>
      <Parameter name="MANUAL_WEIGHT_SQUARE" type="object" value="&lt;Vector&lt;float&gt; 0.0 2000.0 4000.0 6000.0 8000.0&gt;" description="MUSIC spectrum weight for each frequency bin. This is a M order vector. The element represents the frequency points for the square wave. &quot;M&quot; represents the number of key points for the square wave weight. The format is &quot;&amp;lt;Vector&amp;lt;float&amp;gt; 1 2 3 4&amp;gt;&quot;."/>
      <Parameter name="ENABLE_EIGENVALUE_WEIGHT" type="bool" value="true" description="If true, the spatial spectrum is weighted depending on the eigenvalues of a correlation matrix. We do not suggest to use this function with GEVD and GSVD, because the NOISECM changes the eigenvalue drastically. Only useful for SEVD."/>
      <Parameter name="MAXNUM_OUT_PEAKS" type="int" value="-1" description="Maximum number of output peaks. If MAXNUM_OUT_PEAKS = NUM_SOURCE, this is compatible with HARK version 1.0. If MAXNUM_OUT_PEAKS = 0, all local maxima are output. If MAXNUM_OUT_PEAKS &amp;lt; 0, MAXNUM_OUT_PEAKS is set to NUM_SOURCE. If MAXNUM_OUT_PEAKS &amp;gt; 0, number of output peaks is limited to MAXNUM_OUT_PEAKS."/>
      <Parameter name="DEBUG" type="bool" value="false" description="Debug option. If the parameter is true, this node outputs sound localization results to a standard output."/>
    </Node>
    <Node name="node_TextConverter_1" type="TextConverter" x="710" y="360">
      <Parameter name="ENABLE_DEBUG" type="bool" value="true" description="Enable debug print. The same text as output from OUTPUT is printed with standard output."/>
    </Node>
    <Link from="node_AudioStreamFromMic_1" output="AUDIO" to="node_MultiFFT_1" input="INPUT"/>
    <Link from="node_MultiFFT_1" output="OUTPUT" to="node_LocalizeMUSIC_1" input="INPUT"/>
    <Link from="node_LocalizeMUSIC_1" output="OUTPUT" to="node_SourceTracker_1" input="INPUT"/>
    <Link from="node_SourceTracker_1" output="OUTPUT" to="node_PyCodeExecutor3_1" input="SOURCES"/>
    <Link from="node_SourceTracker_1" output="OUTPUT" to="node_TextConverter_1" input="DATA"/>
    <NetOutput name="OUTPUT_1" node="node_PyCodeExecutor3_1" terminal="OUTPUT" object_type="any" description="Dynamically added outputs"/>
    <NetCondition name="CONDITION" node="node_AudioStreamFromMic_1" terminal="NOT_EOF"/>
    <NetOutput name="TEXT" node="node_TextConverter_1" terminal="TEXT" object_type="string" description="Outputs JSON formatted text based on input. Multiple inputs are automatically parsed. One JSON text is output per frame."/>
  </Network>
</Document>
